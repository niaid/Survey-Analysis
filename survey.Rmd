---
title: "Survey Analysis With NHANES Data"
author:
- name: Qinlu (Claire) Wang
  affiliation: BCBB
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

This is the practical tutorial for the Survey Analysis Training. 7 topics will be covered:

  1. Importing NHANES to R
  2. Sampling
  3. Creating replicate weights
  4. Simple summary statistics
  5. Regression Models
  6. Tests in contingency tables
  7. Graphics

### 1. Importing NHANES to R

National Center for Health Statistics (NCHS) has been conducting surveys combining interviews with health/laboratory and physical examination studies since 1959. The end-product, recently known as, National Health and Nutrition Examination Surveys (NHANES) provide cross-sectional data of the health and nutrition of the United States population. This information source has been central to formulating nationwide public health policies and practices.

R package **nhanesA** provides a convenient way to download and analyze NHANES survey data.

```{r}
library(haven) # For reading SAS XPT file from NHANES website
library(survey) # For using survey weights
library(dplyr) # For data wrangling
library(nhanesA)
```

Witin the CDC website, NHANES data are available in 5 categories

* Demographics (DEMO)
* Dietary (DIET)
* Examination (EXAM)
* Laboratory (LAB)
* Questionnaire (Q)

We can obtain the summaries of the downloaded data as follows (see below):
```{r}
demo <- nhanes('DEMO_I')
```

```{r}
names(demo)
```

```{r}
table(demo$DMDHSEDU)
```

```{r}
cumsum(table(demo$DMDHSEDU))
```

```{r}
length(is.na(demo$DMDHSEDU))
```

```{r}
summary(demo)
```

```{r}
head(demo)
```
```{r}
dim(demo)
```

### 2. Sampling

Survey designs are specified using the svydesign function. The main arguments to the the function are id to specify sampling units (PSUs and optionally later stages), strata to specify strata, weights to specify sampling weights, and fpc to specify finite population size corrections. These arguments should be given as formulas, referring to columns in a data frame given as the data argument.

The resulting survey design object contains all the data and meta-data needed for analysis, and will be supplied as an argument to analysis functions.

The survey package contains several subsamples from the California Academic Performance Index, in the api data set. First, we load these data:

```{r}
library(survey)
data(api)
```

#### 2.1 Simple Sampling

```{r}
srs_design <- svydesign(id=~1, fpc=~fpc, data=apisrs) 
srs_design
svytotal(~enroll, srs_design)
svymean(~enroll, srs_design)
```

```{r}
nofpc <- svydesign(id=~1, weights=~pw, data=apisrs) 
nofpc
svytotal(~enroll, nofpc)
svymean(~enroll, nofpc)
```

#### 2.2 Stratified Sampling

The apistrat data frame has stratified independent sample

```{r}
dstrat <- svydesign(id=~1,strata=~stype, weights=~pw, data=apistrat, fpc=~fpc)
dstrat
```

stratified on stype, with sampling weights pw. The fpc variable contains the population size for the stratum. As the schools are sampled independently, each record in the data frame is a separate PSU. This is indicated by id=~1. Since the sampling weights could have been determined from the population size an equivalent declaration would be

```{r}
dstrat <- svydesign(id=~1,strata=~stype,  data=apistrat, fpc=~fpc)
dstrat
```

#### 2.3 Cluster Sampling

The apiclus1 data frame is a cluster sample: all schools in a random sample of school districts.
```{r}
dclus1 <- svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc)
dclus1
```

There is no strata argument as the sampling was not stratified. The variable dnum identifies school districts (PSUs) and is specified as the id argument. Again, the weights argument is optional, as the sampling weights can be computed from the population size. To specify sampling with replacement, simply omit the fpc argument:

```{r}
dclus1 <- svydesign(id=~dnum, weights=~pw, data=apiclus1)
dclus1
```

A design may have strata and clusters. In that case svydesign assumes that the clusters are numbered uniquely across the entire sample, rather than just within a stratum. This enables some sorts of data errors to be detected. If your clusters are only numbered uniquely within a stratum use the option nest=TRUE to specify this and disable the checking.

The apiclus2 data set contains a two-stage cluster sample. First, school districts were sampled. If there were fewer than five schools in the district, all were taken, otherwise a random sample of five.

```{r}
dclus2<-svydesign(id=~dnum+snum, fpc=~fpc1+fpc2, data=apiclus2)
dclus2
```

The multistage nature of the sampling is clear in the id and fpc arguments. At the first stage the sampling units are identified by dnum and the population size by fpc1. At the second stage, units within each school district are identified by snum and the number of units within the district by fpc2. When a finite population correction is not given, and sampling is with replacement, only the first stage of the design is needed. The following two declarations are equivalent for treating the two-stage cluster design as if the first stage were with replacement.

```{r}
dclus2wr <- svydesign(id=~dnum+snum, weights=~pw, data=apiclus2)
dclus2wr

dclus2wr2 <- svydesign(id=~dnum, weights=~pw, data=apiclus2)
dclus2wr2
```

#### 2.4 Application with NHANES data

Copy and rename variables so they are more intuitive. "fpl" is percent of the federal poverty level. It ranges from 0 to 5.
```{r}
demo$fpl        <- demo$INDFMPIR
demo$age        <- demo$RIDAGEYR
demo$gender     <- demo$RIAGENDR
demo$persWeight <- demo$WTINT2YR
demo$psu        <- demo$SDMVPSU
demo$strata     <- demo$SDMVSTRA
nhanesAnalysis <- demo %>%
                    select(fpl,
                           age,
                           gender,
                           persWeight,
                           psu,
                           strata)
```

Convert "gender" to a factor variable. We need to do this so it isn't treated as a continuous variable in our analyses
```{r}
nhanesAnalysis$gender <- as.factor(nhanesAnalysis$gender)
```

```{r}
# Here we use "svydesign" to assign the weights. We will use this new design variable "nhanesDesign" when running our analyses.
 
nhanesDesign <- svydesign(id      = ~psu,
                          strata  = ~strata,
                          weights = ~persWeight,
                          nest    = TRUE,
                          data    = nhanesAnalysis)
 
# Here we use "subset" to tell "nhanesDesign" that we want to only look at a specific subpopulation (i.e., those age between 18-79 years). This is important to do. If you don't do this and just restrict it in a different way your estimates won't have correct SEs.
 
ageDesign <- subset(nhanesDesign, age > 17 &
                                  age < 80)

nhanesDesign
```

```{r}
ageDesign
```

```{r}
svymean(~age, ageDesign, na.rm = TRUE)
```

```{r}
svymean(~gender, ageDesign, na.rm = TRUE)
```

### 3. Creating replicate weights

Replicate weights present in the data file can be specified as an argument to svrepdesign, but it is also possible to create replicate weights from a survey design object.
There are three types of replicate weight that can be created with as.svrepdesign. Jackknife (JK1 and JKn) weights omit one PSU at a time. Balanced repeated replicates (BRR and Fay) omit or downweight half the sample. Bootstrap replicates resample PSUs from an estimated population. All these types of weights are created by as.svrepdesign, according to the type argument. The default is JK1 weights for an unstratified sample and JKn for a stratified sample.

Here we create a survey design object using the one-stage cluster sample from the California Academic Performance Index.

```{r}
data(api)
dclus1<-svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc)
dclus1
```

Converting this design to use unstratified jackknife (JK1) weights is as simple as

```{r}
rclus1<-as.svrepdesign(dclus1)
```

To convert to bootstrap weights, specify the type and the number of bootstrap replicates.
```{r}
bclus1 <- as.svrepdesign(dclus1,type="bootstrap", replicates=100)
```

Balanced Repeated Replicates are designed for surveys with two PSUs in each stratum (although as.svrepdesign will attempt to handle some other designs. Within each replicate each stratum of the sample is split into halves, in a complex design that ensures two PSUs from different strata are in the same half-sample for exactly half the replicates.

This "complete orthogonal balance" is possible only when the number of replicates is a multiple of 4, larger than the number of strata. Even then, constructing a suitable set of replicates may be difficult. The survey package will sometimes use more replicates than are strictly necessary.

Here we create a design from a small data set with 2 PSUs in each stratum.

```{r}
data(scd)
scdnofpc<-svydesign(data=scd, prob=~1, id=~ambulance, strata=~ESA,
                     nest=TRUE)
scdnofpc
```

To convert to use BRR weights, we specify type="BRR".

```{r}
scd2brr <- as.svrepdesign(scdnofpc, type="BRR")
```

Fay's method is a modified version of BRR that uses weights of 2-ρ and ρ rather than 2 and 0 for PSUs in and not in a particular half-sample.

```{r}
scd2fay <- as.svrepdesign(scdnofpc, type="Fay",fay.rho=0.3)
```

### 4. Simple summary statistics

To demonstrate the calculation of simple summary statistics I will use the dclus1 and rclus1 survey objects created in earlier examples. Some information about the designs is provided by the print and summary methods:

```{r}
dclus1
```

```{r}
summary(rclus1) 
```

All the analysis functions take a survey design object as one of the arguments, and use a model formula to specify variables for analysis. First look at svymean.

```{r}
svymean(~api00, dclus1)
```

This asks for the mean (and standard error of the mean) for the variable api00, the year 2000 Academic Performance Index. We can ask for means of more than one variable at a time:

```{r}
svymean(~api00+api99+stype, dclus1)
```

Here we have the means of 1999 and 2000 API and school type (elementary, middle, high). Note that for the factor variable stype the proportion in each category is reported.

The same syntax is used to compute means from the survey object rclus1, but here the standard errors are computed from the jackknife replicate weights and are slightly different.

```{r}
svymean(~api00+api99+stype, rclus1)
```
  
Totals are estimated with svytotal. Here we estimate the total number of students enrolled, and the total number of schools by type, across the California population.

```{r}
svytotal(~enroll+stype, dclus1)
```

Note again that totals for factor variables are interpreted as total numbers in each category.

Again, the syntax is the same for the rclus1 object that incorporates replicate weights:

```{r}
svytotal(~enroll+stype, rclus1)
```

The functions for totals and means can also report the design effect, with the option deff=TRUE

```{r}
svytotal(~enroll+stype, dclus1, deff=TRUE)
```

though this is not currently available with replicate weights.

Ratio estimates are computed with svyratio. This has two formula arguments, specifying one or more numerator variables and one or more denominator variables. In this example we estimate the proportion of students who took the API test from the number who took the test and the number enrolled.

```{r}
svyratio(~api.stu,~enroll, dclus1)
```
 
Again, the syntax is the same for a version with replicate weights

The population variance is estimated with svyvar, with a similar syntax to means and totals

```{r}
svyvar(~api00+api99, rclus1)
```

Quantiles are a more difficult estimation problem. It is easy enough to find a point estimate, but many confidence interval methods fail. There are two confidence interval calculation methods for quantiles in objects created with svydesign. The default method is substantially faster but probably less accurate for tail quantiles or for small data sets.

In addition to specifying the variables and the design object, it is necessary to specify which quantiles to estimate. Here we estimate the median and quartiles.

```{r}
svyquantile(~api00, dclus1, c(.25,.5,.75), ci=TRUE)
```

```{r}
dclus1<-svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc)
(qapi<-svyquantile(~api00, dclus1, c(.25,.5,.75),ci=TRUE, interval.type="score"))
```

```{r}
SE(qapi)
```

The confidence intervals are not symmetric and so cannot be generated by adding and subtracting 1.96 standard errors. Nonetheless, a reasonable estimate of the standard error is the length of the confidence interval divided by (2x1.96).

The syntax for replicate weights is similar. Again, there are two methods of variance estimation. The default is valid for all types of replicate weights and is based on computing a confidence interval for the probability and transforming it. The alternative, directly using the variance of replicates, is not valid for jackknife weights.

##### Tables of summary statistics
As discussed in earlier examples, svyby can be used to estimate statistics in subpopulations and svymean and svytotal give proportions or totals in subpopulations when used on factor variables. In this example we see how to construct reasonably attractive tables of summary statistics using the output from these functions. These examples use the dclus1 survey design object created in an earlier example.

The first example shows the estimation of proportions in the cells of a contingency table: school type (elementary, middle, high) by whether the school met its "comparable improvement" target. The first step is to construct a single factor variable that specifies all the cells in the table and use svymean to estimate proportions

```{r}
a <- svymean(~interaction(stype, comp.imp), design = dclus1)
a
```

This contains all the numbers we need, but the formatting leaves something to be desired. The ftable function reshapes output like this into a flattened table. We specify the variable names and the labels for each level in the rownames argument:

```{r}
b <- ftable(a, rownames = list(stype = c("E", "H",
     "M"), comp.imp = c("No", "Yes")))
b
```

The major remaining fault in the table is that too many digits are given. We can convert to percentages and then round to one decimal place:

```{r}
round(100 * b, 1)
```

The second example deals with a table of means produced by svyby. This is more straightforward, since svyby already knows the variable names and levels. First we estimate the mean of 1999 and 2000 API by school type and comparable improvement target

```{r}
a<-svyby(~api99 + api00, ~stype + sch.wide, rclus1, svymean, keep.var=TRUE)
a
```
Now we convert to a table

```{r}
ftable(a)
```

For variety, we trim the excess digits using the digits argument to print (the previous approach using round would also work).

```{r}
print(ftable(a),digits=3)
```

Note that digits specifies the number of significant digits, rather than decimal places.

### 5. Regression Models

Generalized linear models, including the linear model, are estimated by svyglm. This has almost the same arguments as glm, the difference being that the data argument to glm is replaced by a design argument to svyglm. Similarly, svycoxph fits Cox models to survey data.

In this example we use the dclus2 two-stage cluster sample from the California Academic Performance Index, which was created in an earlier example. The syntax and options for svyglm are the same for designs with and without replicate weights.

The outcome variable is 2000 API, predicted by the proportions of students learning English (ell), receiving subsidized means (means) and having moved to the school within the past year (mobility). This is a linear regression model, so no family argument to svyglm is needed.

```{r}
summary(svyglm(api00 ~ ell + meals + mobility, design = dclus2))
```

A useful property of regression models is that they provide another way to get domain estimates. Suppose we want the mean of api00 for each school type:

```{r}
summary(svyglm(api00~stype-1, dclus2))
```

```{r}
svyby(~api00,~stype,dclus2,svymean, keep.var=TRUE)
```

This equivalence helps in thinking about domain estimators and how they handle more complex designs.

### 6. Tests in contingency tables

R implements two types of test for association in two-way tables, each with further variants. The first type is tests based on the Pearson chi-squared statistic, using theory developed by JNK Rao and Scott. (Annals of Statistics 12:46-60).

A X^2 statistic computed from an estimated population table is too large, because the effective sample size is much smaller than the population size. Even after rescaling, its distribution is not exactly chi-squared. However, a chi-squared or F distribution for the rescaled statistic give reasonable approximations. The default is the F distribution, the "second-order Rao-Scott adjustment".

Using the dclus1 design object constructed in an earlier example we examine whether the proportion of schools meeting their "school-wide growth target" is different by school type. We use the default second-order adjustment and the first-order adjustment (the chi-squared approximation).

```{r}
svytable(~sch.wide + stype, dclus1)
```

```{r}
svychisq(~sch.wide + stype, dclus1)
```

```{r}
svychisq(~sch.wide + stype, dclus1, statistic = "Chisq")
```

The other type of test is a Wald test based on the differences between the observed cell counts and those expected under independence (Koch et al, International Statistical Review 43: 59-78). I believe the statistic="Wald" test is the one used by SUDAAN. Using statistic="adjWald" reduces the statistic when the number of PSUs is small compared to the number of degrees of freedom. Rao & Thomas (JASA 82:630-636) recommend the adjusted version.

```{r}
svychisq(~sch.wide+stype, dclus1, statistic="adjWald")
```

```{r}
svychisq(~sch.wide+stype, dclus1, statistic="Wald")
```

### 7. Graphics

There are (at least) three useful strategies for graphing survey data.

1. Draw a conventional graph and annotate it to indicate sampling weights
2. Graph some feature of the estimated population distribution
3. Simulate a simple random sample from the estimated population distribution and graph that.

The survey package has examples of all three of these in the svyplot and svyhist functions.

The first approach produces the "bubble plot". Here we show the relationship between the 2000 and 1999 API scores for a two-stage cluster sample of California schools. The radius of the bubble for each school is proportional to the sampling weight.

```{r}
data(api)
dclus2<-svydesign(id=~dnum+snum, fpc=~fpc1+fpc2, data=apiclus2)
svyplot(api00~api99, dclus2)
```
The second strategy is used by the hexagonal binning plots and survey-weighted histograms. Hexagonal binning plots divide the screen on a hexagonal grid and show the number of points falling in each hexagon. The survey-weighted hexbin plot shows estimated population numbers in each cell. It requires the "hexbin" package from Bioconductor.

This example uses data from NHANES 2, and shows the estimated relationship between serum iron and serum transferrin in the US population

```{r}
#svyplot(iron~trnsfern,style="hex",dhanes,xlab="Transferrin",ylab="Iron",legend=2)
#svyplot(iron~trnsfern,style="grayhex",dhanes,xlab="Transferrin",ylab="Iron",legend=2)
```

Another example uses the API data and compares the estimated cumulative distribution to the known population cumulative distribution

```{r}
data(api)
dstrat <- svydesign(id = ~1, strata = ~stype, weights = ~pw, data = apistrat,      fpc = ~fpc)
 cdf.est<-svycdf(~enroll+api00+api99, dstrat)
cdf.pop<-ecdf(apipop$enroll)

plot(cdf.pop, main="Population vs estimate",xlab="Enrollment")
lines(cdf.est[[1]],col.points="red")
legend("right",col=c("red","black"),pch=1, legend=c("Estimate","Population"),bty="n",lty=1)
```
###### Smoothing

This example uses data from PEAS Examplar 2, which examines internet use in Scotland from the Scottish Household Survey.

The graph of internet use by age and sex looks like the one in the PEAS examplar, but using svysmooth makes it much easier to produce

```{r}
load("ex2.RData")
shs.des <- svydesign(id=~PSU, weights=~GROSSWT,strata=~STRATUM,data=shs)

plot(c(15,83),c(0,65),type='n',xlab='age',ylab='% internet users')
legend("topright",lty=c(1,1),col=c("blue","red"),legend=c("Male","Female"),bty="n")
lf<-svysmooth(I(100*INTUSE)~AGE,subset(shs.des,SEX=="female" & !is.na(AGE)),bandwidth=10)
lines(lf,col="red")
lm<-svysmooth(I(100*INTUSE)~AGE,subset(shs.des,SEX=="male" & !is.na(AGE)),bandwidth=10)
lines(lm, col="blue")

shs.des <- update(shs.des, agegp=cut(AGE, c(0,25,35,45,55,66,75,Inf)))
means<-svyby(~INTUSE,~agegp+SEX,svymean,design=shs.des, na.rm=TRUE)
points((2:8)*10, means[1:7,3]*100,col="blue")
points((2:8)*10, means[7+1:7,3]*100,col="red")
```

### Reference

1. Survey analysis in R: https://r-survey.r-forge.r-project.org/survey/
2. Survey Data: Design and Examples: https://ehsanx.github.io/SPPH504007SurveyData/docs/
3. Complex Surveys: A Guide to Analysis Using R: https://www.amazon.com/Complex-Surveys-Guide-Analysis-Using/dp/0470284307